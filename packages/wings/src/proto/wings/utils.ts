// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.176.0
//   protoc               unknown
// source: wings/utils.proto

/* eslint-disable */
import Long from "long";
import _m0 from "protobufjs/minimal.js";
import { Timestamp } from "../google/protobuf/timestamp.js";
import { CommittedBatch, PartitionValue } from "./log_metadata.js";

export const protobufPackage = "wings.v1.utils";

/** Represents metadata sent with an ingestion request. */
export interface IngestionRequestMetadata {
  /** A unique identifier for this ingestion request. */
  readonly requestId: bigint;
  /** The partition value associated with this ingestion. */
  readonly partitionValue?:
    | PartitionValue
    | undefined;
  /** Timestamp of when this ingestion was initiated. */
  readonly timestamp?: Date | undefined;
}

/** Represents metadata about a successfully accepted batch of messages. */
export interface AcceptedBatchInfo {
  /** The offset of the first message in the batch. */
  readonly startOffset: bigint;
  /** The offset of the last message in the batch. */
  readonly endOffset: bigint;
  /** The timestamp of the batch. */
  readonly timestamp: Date | undefined;
}

/** Represents metadata about a batch that was rejected. */
export interface RejectedBatchInfo {
  /** The number of messages in the rejected batch. */
  readonly numMessages: number;
}

/** Represents metadata for an ingestion response. */
export interface IngestionResponseMetadata {
  /** Unique identifier for the ingestion request this response refers to. */
  readonly requestId: bigint;
  /** The result of the ingestion request, which may be accepted or rejected. */
  readonly result: CommittedBatch | undefined;
}

function createBaseIngestionRequestMetadata(): IngestionRequestMetadata {
  return { requestId: BigInt("0"), partitionValue: undefined, timestamp: undefined };
}

export const IngestionRequestMetadata = {
  encode(message: IngestionRequestMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.requestId !== BigInt("0")) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId.toString());
    }
    if (message.partitionValue !== undefined) {
      PartitionValue.encode(message.partitionValue, writer.uint32(18).fork()).ldelim();
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): IngestionRequestMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionRequestMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.requestId = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partitionValue = PartitionValue.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionRequestMetadata {
    return {
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : BigInt("0"),
      partitionValue: isSet(object.partitionValue) ? PartitionValue.fromJSON(object.partitionValue) : undefined,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: IngestionRequestMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== BigInt("0")) {
      obj.requestId = message.requestId.toString();
    }
    if (message.partitionValue !== undefined) {
      obj.partitionValue = PartitionValue.toJSON(message.partitionValue);
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(base?: I): IngestionRequestMetadata {
    return IngestionRequestMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(object: I): IngestionRequestMetadata {
    const message = createBaseIngestionRequestMetadata() as any;
    message.requestId = object.requestId ?? BigInt("0");
    message.partitionValue = (object.partitionValue !== undefined && object.partitionValue !== null)
      ? PartitionValue.fromPartial(object.partitionValue)
      : undefined;
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

function createBaseAcceptedBatchInfo(): AcceptedBatchInfo {
  return { startOffset: BigInt("0"), endOffset: BigInt("0"), timestamp: undefined };
}

export const AcceptedBatchInfo = {
  encode(message: AcceptedBatchInfo, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.startOffset !== BigInt("0")) {
      if (BigInt.asUintN(64, message.startOffset) !== message.startOffset) {
        throw new globalThis.Error("value provided for field message.startOffset of type uint64 too large");
      }
      writer.uint32(8).uint64(message.startOffset.toString());
    }
    if (message.endOffset !== BigInt("0")) {
      if (BigInt.asUintN(64, message.endOffset) !== message.endOffset) {
        throw new globalThis.Error("value provided for field message.endOffset of type uint64 too large");
      }
      writer.uint32(16).uint64(message.endOffset.toString());
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AcceptedBatchInfo {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAcceptedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.startOffset = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.endOffset = longToBigint(reader.uint64() as Long);
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AcceptedBatchInfo {
    return {
      startOffset: isSet(object.startOffset) ? BigInt(object.startOffset) : BigInt("0"),
      endOffset: isSet(object.endOffset) ? BigInt(object.endOffset) : BigInt("0"),
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: AcceptedBatchInfo): unknown {
    const obj: any = {};
    if (message.startOffset !== BigInt("0")) {
      obj.startOffset = message.startOffset.toString();
    }
    if (message.endOffset !== BigInt("0")) {
      obj.endOffset = message.endOffset.toString();
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(base?: I): AcceptedBatchInfo {
    return AcceptedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(object: I): AcceptedBatchInfo {
    const message = createBaseAcceptedBatchInfo() as any;
    message.startOffset = object.startOffset ?? BigInt("0");
    message.endOffset = object.endOffset ?? BigInt("0");
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

function createBaseRejectedBatchInfo(): RejectedBatchInfo {
  return { numMessages: 0 };
}

export const RejectedBatchInfo = {
  encode(message: RejectedBatchInfo, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.numMessages !== 0) {
      writer.uint32(8).uint32(message.numMessages);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): RejectedBatchInfo {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRejectedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.numMessages = reader.uint32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RejectedBatchInfo {
    return { numMessages: isSet(object.numMessages) ? globalThis.Number(object.numMessages) : 0 };
  },

  toJSON(message: RejectedBatchInfo): unknown {
    const obj: any = {};
    if (message.numMessages !== 0) {
      obj.numMessages = Math.round(message.numMessages);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(base?: I): RejectedBatchInfo {
    return RejectedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(object: I): RejectedBatchInfo {
    const message = createBaseRejectedBatchInfo() as any;
    message.numMessages = object.numMessages ?? 0;
    return message;
  },
};

function createBaseIngestionResponseMetadata(): IngestionResponseMetadata {
  return { requestId: BigInt("0"), result: undefined };
}

export const IngestionResponseMetadata = {
  encode(message: IngestionResponseMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.requestId !== BigInt("0")) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId.toString());
    }
    if (message.result !== undefined) {
      CommittedBatch.encode(message.result, writer.uint32(18).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): IngestionResponseMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionResponseMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.requestId = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.result = CommittedBatch.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionResponseMetadata {
    return {
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : BigInt("0"),
      result: isSet(object.result) ? CommittedBatch.fromJSON(object.result) : undefined,
    };
  },

  toJSON(message: IngestionResponseMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== BigInt("0")) {
      obj.requestId = message.requestId.toString();
    }
    if (message.result !== undefined) {
      obj.result = CommittedBatch.toJSON(message.result);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(base?: I): IngestionResponseMetadata {
    return IngestionResponseMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(object: I): IngestionResponseMetadata {
    const message = createBaseIngestionResponseMetadata() as any;
    message.requestId = object.requestId ?? BigInt("0");
    message.result = (object.result !== undefined && object.result !== null)
      ? CommittedBatch.fromPartial(object.result)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { readonly $case: string }
    ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { readonly $case: T["$case"] }
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = BigInt(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (globalThis.Number(t.seconds.toString()) || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToBigint(long: Long) {
  return BigInt(long.toString());
}

if (_m0.util.Long !== Long) {
  _m0.util.Long = Long as any;
  _m0.configure();
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}
